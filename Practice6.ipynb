{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cbf5b63-b297-483f-8ef0-91b92a43718e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47bfb360-a9e2-4778-a32f-83cfde2c382d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TicTacToe:\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.board = [0]*9  # 0=empty, 1=X (agent), -1=O (opponent)\n",
    "        self.done = False\n",
    "        self.winner = None\n",
    "        return tuple(self.board)\n",
    "\n",
    "    def available_actions(self):\n",
    "        return [i for i in range(9) if self.board[i] == 0]\n",
    "\n",
    "    def check_winner(self):\n",
    "        b = self.board\n",
    "        wins = [(0,1,2),(3,4,5),(6,7,8),\n",
    "                (0,3,6),(1,4,7),(2,5,8),\n",
    "                (0,4,8),(2,4,6)]\n",
    "        for (i,j,k) in wins:\n",
    "            s = b[i] + b[j] + b[k]\n",
    "            if s == 3:\n",
    "                self.winner, self.done = 1, True\n",
    "                return 1\n",
    "            if s == -3:\n",
    "                self.winner, self.done = -1, True\n",
    "                return -1\n",
    "        if 0 not in b:\n",
    "            self.winner, self.done = 0, True\n",
    "            return 0\n",
    "        return None\n",
    "\n",
    "    def step(self, action, player):\n",
    "        self.board[action] = player\n",
    "        self.check_winner()\n",
    "        reward = 0\n",
    "        if self.done:\n",
    "            if self.winner == 1: reward = 1\n",
    "            elif self.winner == -1: reward = -1\n",
    "            else: reward = 0.5\n",
    "        return tuple(self.board), reward, self.done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "636521cb-fdb1-4a14-80a5-3d0cd4a590cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = {}  # state-action values\n",
    "\n",
    "def get_Q(state):\n",
    "    if state not in Q:\n",
    "        Q[state] = np.zeros(9)\n",
    "    return Q[state]\n",
    "\n",
    "def choose_action(state, available, epsilon=0.1):\n",
    "    if random.random() < epsilon:\n",
    "        return random.choice(available)\n",
    "    q = get_Q(state)\n",
    "    q_masked = np.array([q[i] if i in available else -999 for i in range(9)])\n",
    "    return int(np.argmax(q_masked))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d11bb77-ac0a-40d4-b86b-4dd54958fdf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trained!\n"
     ]
    }
   ],
   "source": [
    "env = TicTacToe()\n",
    "alpha, gamma, epsilon = 0.8, 0.9, 0.1\n",
    "for episode in range(20000):  # ~20k games\n",
    "    state = env.reset()\n",
    "    while not env.done:\n",
    "        # Agent (X)\n",
    "        available = env.available_actions()\n",
    "        action = choose_action(state, available, epsilon)\n",
    "        next_state, reward, done = env.step(action, 1)\n",
    "        if done:\n",
    "            get_Q(state)[action] += alpha * (reward - get_Q(state)[action])\n",
    "            break\n",
    "        # Opponent (O) random\n",
    "        opp_action = random.choice(env.available_actions())\n",
    "        next_state2, reward2, done2 = env.step(opp_action, -1)\n",
    "        if done2:\n",
    "            get_Q(state)[action] += alpha * ((-reward2) - get_Q(state)[action])\n",
    "            break\n",
    "        get_Q(state)[action] += alpha * (reward + gamma * np.max(get_Q(next_state2)) - get_Q(state)[action])\n",
    "        state = next_state2\n",
    "\n",
    "print(\" Trained!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "397c4924-3138-417a-a0dc-ee55809e4ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game start!\n",
      "[[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "[[ 1  0  0]\n",
      " [-1  0  0]\n",
      " [ 0  0  0]]\n",
      "[[ 1  1  0]\n",
      " [-1  0  0]\n",
      " [ 0  0  0]]\n",
      "[[ 1  1  0]\n",
      " [-1  0  0]\n",
      " [ 0 -1  0]]\n",
      "[[ 1  1  1]\n",
      " [-1  0  0]\n",
      " [ 0 -1  0]]\n",
      "Agent wins!\n"
     ]
    }
   ],
   "source": [
    "def play_one_game():\n",
    "    state = env.reset()\n",
    "    env.done = False\n",
    "    print(\"Game start!\")\n",
    "    while not env.done:\n",
    "        # Agent move\n",
    "        act = choose_action(state, env.available_actions(), epsilon=0)\n",
    "        state, _, done = env.step(act, 1)\n",
    "        b = env.board\n",
    "        print(np.array(b).reshape(3,3))\n",
    "        if done: break\n",
    "        # Opponent random\n",
    "        opp = random.choice(env.available_actions())\n",
    "        state, _, done = env.step(opp, -1)\n",
    "        print(np.array(b).reshape(3,3))\n",
    "    if env.winner == 1:\n",
    "        print(\"Agent wins!\")\n",
    "    elif env.winner == -1:\n",
    "        print(\"Opponent wins!\")\n",
    "    else:\n",
    "        print(\"Draw!\")\n",
    "\n",
    "play_one_game()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c376594e-9d66-4d9a-821c-4fd794635edb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2438ea-2a54-48a4-bb08-46e2be467968",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
